{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da616f3f-154c-4d40-983b-3b5756eddeac","_uuid":"b3c557bc-11f3-4724-ab6e-b6a2f090aa84","collapsed":false,"execution":{"iopub.execute_input":"2023-06-12T08:35:32.445263Z","iopub.status.busy":"2023-06-12T08:35:32.444942Z","iopub.status.idle":"2023-06-12T08:35:32.463142Z","shell.execute_reply":"2023-06-12T08:35:32.462075Z","shell.execute_reply.started":"2023-06-12T08:35:32.445234Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"0a8c9082-53ef-422c-a898-3ee2c7730151","_uuid":"57523f26-3592-4e14-ba82-63a3af82d39f","trusted":true},"source":["# Text Generation using LSTM \n","\n","This is actually a fun project, since we are generating cute baby names using RNN \n","\n","The credit for the code goes to : **Alladin Persson** \n","_aladin.persson@hotmail.com_\n","His youtube channel :- https://www.youtube.com/c/AladdinPersson"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b5e9a0b-aa4d-45ce-926d-8b21b2673cfd","_uuid":"6d87e377-14f5-4000-8a39-12ce8dd6ab42","collapsed":false,"execution":{"iopub.execute_input":"2023-06-12T08:35:32.466253Z","iopub.status.busy":"2023-06-12T08:35:32.465924Z","iopub.status.idle":"2023-06-12T08:35:37.382991Z","shell.execute_reply":"2023-06-12T08:35:37.381904Z","shell.execute_reply.started":"2023-06-12T08:35:32.466223Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Importing dependencies for the project\n","\n","import torch \n","import torch.nn as nn \n","import string \n","import re \n","import random \n","import unidecode"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8b78c53-1f5a-48f9-a9c0-d37664317d4e","_uuid":"b2b00708-0cb9-4395-ac95-4cb03db15433","collapsed":false,"execution":{"iopub.execute_input":"2023-06-12T08:35:37.385394Z","iopub.status.busy":"2023-06-12T08:35:37.384478Z","iopub.status.idle":"2023-06-12T08:35:37.515513Z","shell.execute_reply":"2023-06-12T08:35:37.514253Z","shell.execute_reply.started":"2023-06-12T08:35:37.385361Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4317e983-baad-4d4b-875f-de8746128df5","_uuid":"a11904bf-81d9-46ec-8686-c4216e397416","collapsed":false,"execution":{"iopub.execute_input":"2023-06-12T08:35:37.519648Z","iopub.status.busy":"2023-06-12T08:35:37.518020Z","iopub.status.idle":"2023-06-12T08:35:37.528004Z","shell.execute_reply":"2023-06-12T08:35:37.526661Z","shell.execute_reply.started":"2023-06-12T08:35:37.519611Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["all_characters = string.printable\n","n_characters = len(all_characters)\n","n_characters"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f4cd3c7-ba64-46dc-8e46-4546f15037b5","_uuid":"8d9534f3-021b-434d-9849-c13458db5e3b","collapsed":false,"execution":{"iopub.execute_input":"2023-06-12T08:35:37.536224Z","iopub.status.busy":"2023-06-12T08:35:37.534735Z","iopub.status.idle":"2023-06-12T08:35:42.356548Z","shell.execute_reply":"2023-06-12T08:35:42.355469Z","shell.execute_reply.started":"2023-06-12T08:35:37.536172Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["file = unidecode.unidecode(open(\"/kaggle/input/babynames/names.txt\").read())\n","# file"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"1dff0a8e-3c12-4880-aceb-270eb2bfabf6","_uuid":"0d4723cc-c145-40cb-a480-1dca1995ccc5","trusted":true},"source":["# RNN class"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe82634c-5e15-46df-bea9-6c13bee65730","_uuid":"b5725803-f2ff-425e-b9b5-29f827ebbe5d","collapsed":false,"execution":{"iopub.execute_input":"2023-06-12T08:35:42.358343Z","iopub.status.busy":"2023-06-12T08:35:42.357898Z","iopub.status.idle":"2023-06-12T08:35:42.368106Z","shell.execute_reply":"2023-06-12T08:35:42.367026Z","shell.execute_reply.started":"2023-06-12T08:35:42.358310Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class RNN(nn.Module):\n","    \n","    def __init__(self , input_size , hidden_size ,num_layers, output_size):\n","        super().__init__()\n","        \n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.num_layers = num_layers\n","        \n","        self.embed = nn.Embedding(input_size ,hidden_size)\n","        self.lstm = nn.LSTM(hidden_size , hidden_size , num_layers , batch_first = True)\n","        self.fc = nn.Linear(hidden_size , output_size)\n","        \n","    def forward(self,x, hidden, cell):\n","        out = self.embed(x)\n","        out , (hidden,cell) = self.lstm(out.unsqueeze(1) , (hidden,cell ))\n","        out = self.fc(out.reshape(out.shape[0] , -1))\n","        return out, (hidden ,cell)\n","    \n","    def init_hidden(self,batch_size):\n","        hidden = torch.zeros(self.num_layers , batch_size , self.hidden_size).to(device)\n","        cell = torch.zeros(self.num_layers , batch_size , self.hidden_size).to(device)\n","        \n","        return hidden , cell"]},{"attachments":{},"cell_type":"markdown","metadata":{"_cell_guid":"c5de9111-ca28-4604-8e2c-23f6233761c6","_uuid":"9d61db36-a01d-43e5-9c28-1b1b49ad037c","trusted":true},"source":["# Generator class"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f5a0c37-ddd0-482b-ba75-fae891bf2524","_uuid":"d9ec3bf0-c1ae-450a-b0ef-7f00cda11811","collapsed":false,"execution":{"iopub.execute_input":"2023-06-12T08:35:42.370227Z","iopub.status.busy":"2023-06-12T08:35:42.369638Z","iopub.status.idle":"2023-06-12T08:35:42.392477Z","shell.execute_reply":"2023-06-12T08:35:42.391456Z","shell.execute_reply.started":"2023-06-12T08:35:42.370194Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class Generator: \n","    \n","    def __init__(self):\n","        self.chunk_len = 250\n","        self.epochs = 1000\n","        self.batch_size = 1\n","        self.print_every = 50\n","        self.hidden_size = 256 \n","        self.num_layers = 2\n","        self.lr = 0.003 \n","        \n","    def char_tensor(self , string):\n","        \n","        tensor = torch.zeros(len(string)).long()\n","        for c in range(len(string)):\n","            tensor[c] = all_characters.index(string[c])\n","        return tensor\n","    \n","    def get_random_batch(self):\n","        start_idx = random.randint(0, len(file) - self.chunk_len)\n","        end_idx = start_idx + self.chunk_len +1 \n","        text_str = file[start_idx : end_idx]\n","        \n","        text_input = torch.zeros(self.batch_size , self.chunk_len)\n","        text_target = torch.zeros(self.batch_size , self.chunk_len)\n","        \n","        for i in range(self.batch_size):\n","            text_input[i,:] = self.char_tensor(text_str[:-1])\n","            text_target[i,:] = self.char_tensor(text_str[1:])\n","            \n","        return text_input.long() , text_target.long()\n","    \n","    def generate(self , initial_str = \"A\" , predict_len = 100 , temperature = 0.85):\n","        \"\"\"\n","        :params \n","        initial_str :str ,\n","        predict_len : int ,\n","        temperature : float, \n","        \"\"\"\n","        hidden, cell = self.rnn.init_hidden(batch_size = self.batch_size)\n","        initial_input = self.char_tensor(initial_str)\n","        predicted = initial_str \n","        \n","        for p in range(len(initial_str) - 1):\n","            _, (hidden, cell) = self.rnn(\n","                initial_input[p].view(1).to(device), hidden, cell\n","            )\n","\n","        last_char = initial_input[-1]\n","\n","        for p in range(predict_len):\n","            output, (hidden, cell) = self.rnn(\n","                last_char.view(1).to(device), hidden, cell\n","            )\n","            output_dist = output.data.view(-1).div(temperature).exp()\n","            top_char = torch.multinomial(output_dist, 1)[0]\n","            predicted_char = all_characters[top_char]\n","            predicted += predicted_char\n","            last_char = self.char_tensor(predicted_char)\n","\n","        return predicted\n","    \n","    def train(self):\n","        \n","        self.rnn = RNN(\n","            n_characters , \n","            self.hidden_size , \n","            self.num_layers,  \n","            n_characters\n","        ).to(device)\n","        optimizer = torch.optim.Adam(self.rnn.parameters() , lr = self.lr)\n","        criterion = nn.CrossEntropyLoss()\n","#         writer  =\n","        \n","        print(\"=== Started Training ===\")\n","        for epoch in range(self.epochs+1):\n","            inp , target = self.get_random_batch()\n","            hidden, cell = self.rnn.init_hidden(self.batch_size)\n","            \n","            self.rnn.zero_grad()\n","            loss = 0 \n","            inp = inp.to(device)\n","            target = target.to(device)\n","            \n","            for c in range(self.chunk_len):\n","                output, (hidden, cell) = self.rnn(inp[:, c], hidden, cell)\n","                loss += criterion(output, target[:, c])\n","\n","            loss.backward()\n","            optimizer.step()\n","            loss = loss.item() / self.chunk_len\n","            \n","            if epoch % self.print_every ==0:\n","                print(f\"Loss : {loss}\")\n","                print(self.generate())"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68b4d4e9-c3f0-4168-bb84-8741a01798e4","_uuid":"1c674b4c-4e0e-4a2c-87f2-6f1b19fc7001","collapsed":false,"execution":{"iopub.execute_input":"2023-06-12T08:35:42.395354Z","iopub.status.busy":"2023-06-12T08:35:42.394797Z","iopub.status.idle":"2023-06-12T08:39:43.064690Z","shell.execute_reply":"2023-06-12T08:39:43.063495Z","shell.execute_reply.started":"2023-06-12T08:35:42.395312Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["gennames = Generator()\n","gennames.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de0dcc88-a503-43e8-9461-3dfb13201707","_uuid":"9f47eeba-30c4-465c-8db8-fe1f99d8de46","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31803239-1387-403c-af84-6fc96a8c236e","_uuid":"1c101814-0dfb-4af5-bc8f-280e55939131","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
